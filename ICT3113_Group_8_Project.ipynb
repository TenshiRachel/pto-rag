{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO — Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is Group 8's notebook for the ICT3113 Performance Testing and Optimization project following the required structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the company’s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "COMPANY_NAME = \"NVIDIA\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3–5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e08f5a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e08f5a0",
        "outputId": "7a862746-9fc9-4d33-8aeb-024b2a4345c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-win_amd64.whl.metadata (5.2 kB)\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: openai in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.35.13)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.0)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "     ---------------------------------------- 0.0/42.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 42.8/42.8 kB 1.0 MB/s eta 0:00:00\n",
            "Collecting langchain-core<2.0.0,>=0.3.78 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community)\n",
            "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
            "  Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
            "  Downloading langsmith-0.4.34-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.2.6)\n",
            "Collecting openai\n",
            "  Downloading openai-2.3.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n",
            "Collecting jiter<1,>=0.10.0 (from openai)\n",
            "  Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken) (2024.7.24)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (10.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
            "     ---------------------------------------- 0.0/48.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 48.5/48.5 kB 2.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (44.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=0.3.78->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
            "     ---------------------------------------- 0.0/43.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 43.0/43.0 kB 2.0 MB/s eta 0:00:00\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.2.1)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
            "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain-community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in c:\\users\\cryst\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   --------------------- ------------------ 1.4/2.5 MB 29.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 32.3 MB/s eta 0:00:00\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "   ---------------------------------------- 0.0/76.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 76.0/76.0 kB 4.1 MB/s eta 0:00:00\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-win_amd64.whl (18.2 MB)\n",
            "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 2.1/18.2 MB 43.8 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 5.2/18.2 MB 55.2 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 8.4/18.2 MB 59.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 11.5/18.2 MB 73.1 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 14.4/18.2 MB 72.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  17.8/18.2 MB 72.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  18.2/18.2 MB 65.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 18.2/18.2 MB 50.4 MB/s eta 0:00:00\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading openai-2.3.0-py3-none-any.whl (999 kB)\n",
            "   ---------------------------------------- 0.0/999.8 kB ? eta -:--:--\n",
            "   --------------------------------------- 999.8/999.8 kB 66.0 MB/s eta 0:00:00\n",
            "Downloading pypdf-6.1.1-py3-none-any.whl (323 kB)\n",
            "   ---------------------------------------- 0.0/323.5 kB ? eta -:--:--\n",
            "   --------------------------------------- 323.5/323.5 kB 19.6 MB/s eta 0:00:00\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "   ---------------------------------------- 0.0/60.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 60.0/60.0 kB 3.1 MB/s eta 0:00:00\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
            "   ----------------------- ---------------- 3.4/5.6 MB 105.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.6/5.6 MB 88.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.6/5.6 MB 59.7 MB/s eta 0:00:00\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
            "Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl (203 kB)\n",
            "   ---------------------------------------- 0.0/203.5 kB ? eta -:--:--\n",
            "   --------------------------------------- 203.5/203.5 kB 12.9 MB/s eta 0:00:00\n",
            "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.0/1.0 MB 63.0 MB/s eta 0:00:00\n",
            "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
            "   ---------------------------------------- 0.0/449.8 kB ? eta -:--:--\n",
            "   --------------------------------------- 449.8/449.8 kB 27.5 MB/s eta 0:00:00\n",
            "Downloading langsmith-0.4.34-py3-none-any.whl (386 kB)\n",
            "   ---------------------------------------- 0.0/387.0 kB ? eta -:--:--\n",
            "   --------------------------------------- 387.0/387.0 kB 23.5 MB/s eta 0:00:00\n",
            "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
            "   ---------------------------------------- 0.0/48.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 48.6/48.6 kB ? eta 0:00:00\n",
            "Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
            "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
            "   ---------------------------------------  2.9/2.9 MB 92.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.9/2.9 MB 62.6 MB/s eta 0:00:00\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "   ---------------------------------------- 0.0/64.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 64.7/64.7 kB 3.4 MB/s eta 0:00:00\n",
            "Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.1/2.1 MB 45.1 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
            "   ---------------------------------------- 0.0/299.9 kB ? eta -:--:--\n",
            "   --------------------------------------- 299.9/299.9 kB 19.3 MB/s eta 0:00:00\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 50.9/50.9 kB 2.5 MB/s eta 0:00:00\n",
            "Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl (131 kB)\n",
            "   ---------------------------------------- 0.0/131.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 131.4/131.4 kB 7.6 MB/s eta 0:00:00\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
            "   ---------------------------------------- 0.0/506.3 kB ? eta -:--:--\n",
            "   --------------------------------------- 506.3/506.3 kB 16.0 MB/s eta 0:00:00\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: zstandard, typing-inspection, requests, rank-bm25, pypdfium2, pypdf, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, httpx-sse, greenlet, faiss-cpu, typing-inspect, SQLAlchemy, requests-toolbelt, jsonpatch, pydantic-settings, pdfminer.six, openai, langsmith, dataclasses-json, pdfplumber, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.35.13\n",
            "    Uninstalling openai-1.35.13:\n",
            "      Successfully uninstalled openai-1.35.13\n",
            "Successfully installed SQLAlchemy-2.0.44 dataclasses-json-0.6.7 faiss-cpu-1.12.0 greenlet-3.2.4 httpx-sse-0.4.3 jiter-0.11.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-community-0.3.31 langchain-core-0.3.79 langchain-openai-0.3.35 langchain-text-splitters-0.3.11 langsmith-0.4.34 marshmallow-3.26.1 mypy-extensions-1.1.0 openai-2.3.0 orjson-3.11.3 pdfminer.six-20250506 pdfplumber-0.11.7 pydantic-settings-2.11.0 pypdf-6.1.1 pypdfium2-4.30.0 rank-bm25-0.2.2 requests-2.32.5 requests-toolbelt-1.0.0 typing-inspect-0.9.0 typing-inspection-0.4.2 zstandard-0.25.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-intel 2.17.0 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies for ingestion pipeline\n",
        "%pip install langchain-community langchain-openai faiss-cpu rank-bm25 openai tiktoken pypdf pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "rjT6Q12Sdr3t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjT6Q12Sdr3t",
        "outputId": "c12fd35c-e068-4173-b2ae-5e7d348efa77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyinstrument\n",
            "  Downloading pyinstrument-5.1.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
            "Downloading pyinstrument-5.1.1-cp312-cp312-win_amd64.whl (125 kB)\n",
            "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
            "   ---------------------------------------  122.9/125.0 kB 3.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 125.0/125.0 kB 2.4 MB/s eta 0:00:00\n",
            "Installing collected packages: pyinstrument\n",
            "Successfully installed pyinstrument-5.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install pyinstrument"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WU1IQ5-Ta4ks",
      "metadata": {
        "id": "WU1IQ5-Ta4ks"
      },
      "source": [
        "Import libraries for ingestion pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "KOXp3fSTa22D",
      "metadata": {
        "id": "KOXp3fSTa22D"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import glob\n",
        "import json\n",
        "import re\n",
        "import pdfplumber\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.schema import Document\n",
        "from langchain.retrievers import SVMRetriever\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from typing import List, Dict, Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I5LFZwzdIF66",
      "metadata": {
        "id": "I5LFZwzdIF66"
      },
      "source": [
        "PDF Parser and Chunking (Using pdfplumber)\n",
        "1. Extracts words from pdf\n",
        "2. Detects sections\n",
        "3. Returns langchain Document object with page content and metadata containing page number, report name, section, and type of content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "tuOHUEdWIjc2",
      "metadata": {
        "id": "tuOHUEdWIjc2"
      },
      "outputs": [],
      "source": [
        "def detect_section(page, text, min_size_diff=2.0):\n",
        "    \"\"\"\n",
        "    Try to extract the section title from page text using regex patterns or font size, weight.\n",
        "    Handles 10-K, 10Q, Presentations, Investor PDFs and similar formats.\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        r\"(Item\\s+\\d+[A-Za-z]?.\\s*[A-Z][^\\n]+)\",  # e.g. \"Item 7. Management’s Discussion...\"\n",
        "        r\"(ITEM\\s+\\d+[A-Z]?.\\s*[A-Z][^\\n]+)\",     # uppercase variant\n",
        "        r\"(^[A-Z][A-Z\\s]{10,})\"                   # fallback for all-caps section titles\n",
        "    ]\n",
        "    for p in patterns:\n",
        "        m = re.search(p, text)\n",
        "        if m:\n",
        "            return m.group(1).strip()\n",
        "\n",
        "    # For presentation decks/investor pdfs\n",
        "    try:\n",
        "        words = page.extract_words(extra_attrs=[\"size\", \"fontname\"])\n",
        "        if not words:\n",
        "            return None\n",
        "\n",
        "        from collections import defaultdict\n",
        "        lines = defaultdict(list)\n",
        "\n",
        "        # Group words by y-position\n",
        "        for w in words:\n",
        "            lines[round(w[\"top\"], -1)].append(w)\n",
        "\n",
        "        # Compute global average font size to compare against\n",
        "        avg_font_size = sum(float(w[\"size\"]) for w in words) / len(words)\n",
        "\n",
        "        # Define line scoring function\n",
        "        def score_line(line):\n",
        "            avg_size = sum(float(w[\"size\"]) for w in line) / len(line)\n",
        "            bold_bonus = any(\"Bold\" in w[\"fontname\"] or \"Black\" in w[\"fontname\"] for w in line)\n",
        "            return avg_size + (3 if bold_bonus else 0), avg_size\n",
        "\n",
        "        # Score all lines\n",
        "        scored_lines = [(y, line, *score_line(line)) for y, line in lines.items()]\n",
        "        if not scored_lines:\n",
        "            return None\n",
        "\n",
        "        # Pick the top scoring line\n",
        "        _, best_line, best_score, best_size = max(scored_lines, key=lambda x: x[2])\n",
        "\n",
        "        # If the line isn't significantly larger or bold, discard it\n",
        "        if best_size < avg_font_size + min_size_diff:\n",
        "            # (e.g. all text is 10pt, best line is 11pt → not a section)\n",
        "            return None\n",
        "\n",
        "        # Skip lines that look too long (to avoid full sentences)\n",
        "        if len(best_line) > 20:\n",
        "            return None\n",
        "\n",
        "        section_title = \" \".join(w[\"text\"] for w in best_line)\n",
        "        return section_title.strip() if section_title else None\n",
        "\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def parse_pdf_with_tables(pdf_path, report_name, year=None):\n",
        "    text_docs, table_docs = [], []\n",
        "    current_section = None  # rolling context\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages, start=1):\n",
        "            text = page.extract_text() or \"\"\n",
        "            tables = page.extract_tables() or []\n",
        "\n",
        "            # --- Try to detect section header ---\n",
        "            section = detect_section(page, text)\n",
        "            if section:\n",
        "                current_section = section  # update rolling section\n",
        "\n",
        "            # --- Create text Document ---\n",
        "            text_docs.append(\n",
        "                Document(\n",
        "                    page_content=text,\n",
        "                    metadata={\n",
        "                        \"page\": i,\n",
        "                        \"report\": report_name,\n",
        "                        \"year\": year,\n",
        "                        \"section\": current_section,\n",
        "                        \"type\": \"text\"\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # --- Create table Documents ---\n",
        "            for t in tables:\n",
        "                cleaned_table = [\n",
        "                    [cell if cell is not None else \"\" for cell in row]\n",
        "                    for row in t\n",
        "                ]\n",
        "                table_text = \"\\n\".join([\"\\t\".join(row) for row in cleaned_table])\n",
        "                table_docs.append(\n",
        "                    Document(\n",
        "                        page_content=table_text,\n",
        "                        metadata={\n",
        "                            \"page\": i,\n",
        "                            \"report\": report_name,\n",
        "                            \"year\": year,\n",
        "                            \"section\": current_section,\n",
        "                            \"type\": \"table\"\n",
        "                        }\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    return text_docs, table_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8HL2Ve2uhwDA",
      "metadata": {
        "id": "8HL2Ve2uhwDA"
      },
      "source": [
        "Main ingestion pipeline\n",
        "\n",
        "1.   Loops over all pdfs in folder\n",
        "2.   Checks cache for parsed pdf\n",
        "3.   Load from cache if exists, avoiding re-parsing pdf\n",
        "4.   Save to cache after parsing\n",
        "5.   Use parallel processing to parse pdfs in parallel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6c3m1Jvfhxyb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c3m1Jvfhxyb",
        "outputId": "5119b3f5-7f6e-4ee9-fa0b-495e170c2b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY21_10K.pdf ...\n",
            "\n",
            "Parsing FY22_10K.pdf ...\n",
            "\n",
            "Parsing FY23_10K.pdf ...\n",
            "\n",
            "Parsing FY24Q1_10Q.pdf ...\n",
            "\n",
            "Parsing FY24Q2_10Q.pdf ...\n",
            "\n",
            "Parsing FY24Q3_10Q.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern4' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern5' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern6' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern7' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern8' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern9' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern10' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern11' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern12' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern13' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern14' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern15' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern16' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern17' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern18' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern19' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern20' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern21' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern22' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern23' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern24' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern26' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern27' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern28' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern4' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern4' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern5' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern6' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern7' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern8' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern9' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern10' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern11' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern12' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern13' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern14' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern4' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern5' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern6' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern7' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern8' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern9' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern10' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern11' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern12' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern13' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern14' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern4' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern5' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern6' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern7' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern8' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern9' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern10' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern11' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern12' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern13' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern14' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern15' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern16' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern17' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern18' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern19' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern20' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern21' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern22' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern23' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern24' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern26' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern27' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern28' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern2' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern3' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern4' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern5' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern6' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern7' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern8' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern9' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern10' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern11' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern12' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern13' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern14' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern15' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern16' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY24_10K.pdf ...\n",
            "\n",
            "Parsing FY25Q1_10Q.pdf ...\n",
            "\n",
            "Parsing FY25Q2_10Q.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P46' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY25Q2_QuarterlyPresentation.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P195' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P232' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P269' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P306' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P343' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P380' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P417' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P454' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY25Q3_10Q.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P46' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY25Q3_QuarterlyPresentation.pdf ...\n",
            "\n",
            "Parsing FY25Q4_PR.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P46' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY25Q4_QuarterlyPresentation.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P132' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P165' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P198' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P231' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P288' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY25_10K.pdf ...\n",
            "\n",
            "Parsing FY26Q1_10Q.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY26Q1_PR.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P46' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY26Q1_QuarterlyPresentation.pdf ...\n",
            "\n",
            "Parsing FY26Q2_10Q.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'Pattern1' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY26Q2_PR.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P46' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing FY26Q2_QuarterlyPresentation.pdf ...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cannot set gray non-stroke color because /'P129' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P135' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P143' is an invalid float value\n",
            "Cannot set gray non-stroke color because /'P227' is an invalid float value\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2039 parsed documents in 658.26s.\n"
          ]
        }
      ],
      "source": [
        "# --- Parameters ---\n",
        "pdf_folder = \"data/\"\n",
        "\n",
        "PARSED_DIR = \"cache/parsed_pdfs\"\n",
        "os.makedirs(PARSED_DIR, exist_ok=True)\n",
        "\n",
        "def parse_pdf_cached(pdf_path, report_name, year=None):\n",
        "    cache_file = os.path.join(PARSED_DIR, f\"{report_name}.json\")\n",
        "\n",
        "    try:\n",
        "        # --- If cached and file not modified, skip re-parsing ---\n",
        "        pdf_mtime = os.path.getmtime(pdf_path)\n",
        "        if os.path.exists(cache_file):\n",
        "            # cache_mtime = os.path.getmtime(cache_file)\n",
        "            # if cache_mtime > pdf_mtime:\n",
        "            print(f\"Using cached parse for {report_name}\\n\")\n",
        "            with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "            docs = [Document(**d) for d in data]\n",
        "            return docs\n",
        "\n",
        "        # --- Otherwise, parse fresh ---\n",
        "        print(f\"Parsing {os.path.basename(pdf_path)} ...\\n\")\n",
        "        text_docs, table_docs = parse_pdf_with_tables(pdf_path, report_name, year)\n",
        "        docs = text_docs + table_docs\n",
        "\n",
        "        # Save to cache\n",
        "        serializable_docs = [\n",
        "            {\"page_content\": d.page_content, \"metadata\": d.metadata}\n",
        "            for d in docs\n",
        "        ]\n",
        "        with open(cache_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(serializable_docs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        return docs\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing PDF {report_name}: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# --- Measure time!! ----\n",
        "start_total = time.perf_counter()\n",
        "all_docs = []\n",
        "\n",
        "def process_pdf(pdf_path):\n",
        "    report_name = os.path.basename(pdf_path).replace(\".pdf\", \"\")\n",
        "    return parse_pdf_cached(pdf_path, report_name)\n",
        "\n",
        "for pdf_path in glob.glob(os.path.join(pdf_folder, \"*.pdf\")):\n",
        "    doc = process_pdf(pdf_path)\n",
        "    all_docs.extend(doc)\n",
        "\n",
        "# with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "#     results = list(executor.map(process_pdf, glob.glob(os.path.join(pdf_folder, \"*.pdf\"))))\n",
        "#     for docs in results:\n",
        "#         all_docs.extend(docs)\n",
        "\n",
        "elapsed_total = time.perf_counter() - start_total\n",
        "print(f\"Loaded {len(all_docs)} parsed documents in {elapsed_total:.2f}s.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4y-wQYGIe-DE",
      "metadata": {
        "id": "4y-wQYGIe-DE"
      },
      "source": [
        "Chunking\n",
        "1. Uses langchain's Recursive Character Text splitter to split documents\n",
        "2. Returns chunked documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Y2RMsExxeFX6",
      "metadata": {
        "id": "Y2RMsExxeFX6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunked into 6354 total segments.\n",
            "Parsed and chunked 2039 total text segments from 21 PDFs.\n",
            "\n",
            "  _     ._   __/__   _ _  _  _ _/_   Recorded: 02:10:49  Samples:  398\n",
            " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.717     CPU time: 0.672\n",
            "/   _/                      v5.1.1\n",
            "\n",
            "Profile at C:\\Users\\cryst\\AppData\\Local\\Temp\\ipykernel_12512\\492970387.py:3\n",
            "\n",
            "\u001b[31m0.716\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZMQInteractiveShell.run_ast_nodes\u001b[0m  \u001b[2mIPython\\core\\interactiveshell.py:3418\u001b[0m\n",
            "└─ \u001b[31m0.715\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m..\\..\\..\\Temp\\ipykernel_12512\\492970387.py:1\u001b[0m\n",
            "   └─ \u001b[31m0.714\u001b[0m \u001b[48;5;24m\u001b[38;5;15mchunk_documents\u001b[0m  \u001b[2m..\\..\\..\\Temp\\ipykernel_12512\\492970387.py:10\u001b[0m\n",
            "      └─ \u001b[31m0.713\u001b[0m RecursiveCharacterTextSplitter.split_documents\u001b[0m  \u001b[2mlangchain_text_splitters\\base.py:97\u001b[0m\n",
            "            [27 frames hidden]  \u001b[2mlangchain_text_splitters, langchain_c...\u001b[0m\n",
            "               \u001b[33m0.346\u001b[0m Document.__init__\u001b[0m  \u001b[2mlangchain_core\\load\\serializable.py:113\u001b[0m\n",
            "               └─ \u001b[33m0.337\u001b[0m [self]\u001b[0m  \u001b[2mlangchain_core\\load\\serializable.py\u001b[0m\n",
            "\n",
            "\n",
            "Total elapsed time: 0.7155587999950512\n"
          ]
        }
      ],
      "source": [
        "from pyinstrument import Profiler\n",
        "prof = Profiler(async_mode=\"disabled\")\n",
        "prof.start()\n",
        "\n",
        "start_total = time.perf_counter()\n",
        "\n",
        "max_chunk_size = 800\n",
        "chunk_overlap = 100\n",
        "\n",
        "def chunk_documents(all_docs, chunk_size=max_chunk_size, chunk_overlap=chunk_overlap):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    return splitter.split_documents(all_docs)\n",
        "\n",
        "chunked_docs = chunk_documents(all_docs, max_chunk_size, chunk_overlap)\n",
        "print(f\"Chunked into {len(chunked_docs)} total segments.\")\n",
        "\n",
        "print(f\"Parsed and chunked {len(all_docs)} total text segments from {len(glob.glob(pdf_folder + '*.pdf'))} PDFs.\")\n",
        "elapsed_total = time.perf_counter() - start_total\n",
        "\n",
        "prof.stop()\n",
        "print(prof.output_text(unicode=True, color=True))\n",
        "prof.last_session.save(\"01_Chunking.pyisession\")\n",
        "html_output = prof.output_html()\n",
        "with open(\"01_Chunking.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_output)\n",
        "print(f\"Total elapsed time: {elapsed_total}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540b7020",
      "metadata": {
        "id": "540b7020"
      },
      "outputs": [],
      "source": [
        "# # TODO: Implement baseline retrieval + generation\n",
        "# # Take a query -> Retrieve relevant chunks -> Feed to LLM -> answer\n",
        "\n",
        "# # number of docs to retrieve per query\n",
        "# bm25_k = 10\n",
        "# faiss_k = 12\n",
        "\n",
        "# # FAISS Vector Index\n",
        "# faiss_store = FAISS.from_documents(chunked_docs, OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
        "# faiss_store.save_local(\"faiss_index\")\n",
        "\n",
        "# print(\"FAISS vector index built and saved locally.\")\n",
        "\n",
        "# # BM25 Keyword Index\n",
        "# bm25_retriever = BM25Retriever.from_documents(chunked_docs)\n",
        "# bm25_retriever.k = bm25_k\n",
        "\n",
        "# print(\"BM25 keyword retriever ready.\")\n",
        "\n",
        "# print(\"Ingestion complete — FAISS and BM25 indices are ready.\\n\")\n",
        "\n",
        "# # Test Prompt\n",
        "# question = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "\n",
        "# # Test FAISS vector index\n",
        "# faiss_retriever = faiss_store.as_retriever(search_kwargs={\"k\": faiss_k})\n",
        "# test_faiss_docs = faiss_retriever.invoke(question)\n",
        "# print('Using FAISS')\n",
        "# print(test_faiss_docs[0].page_content)\n",
        "# print(test_faiss_docs[0].metadata)\n",
        "# print('\\n')\n",
        "\n",
        "# # Test BM25 retriever\n",
        "# test_bm25_docs = bm25_retriever.invoke(question)\n",
        "# print('Using BM25')\n",
        "# print(test_bm25_docs[0].page_content)\n",
        "# print(test_bm25_docs[0].metadata)\n",
        "# print('\\n')\n",
        "\n",
        "# # Test SVM retriever\n",
        "# # svm_retriever = SVMRetriever.from_documents(chunked_docs, embeddings=embedding_model)\n",
        "# # svm_retriever.k = 10\n",
        "# # test_svm_docs = svm_retriever.invoke(question)\n",
        "# # print('Using SVM:')\n",
        "# # print(test_svm_docs[0].page_content)\n",
        "# # print(test_svm_docs[0].metadata)\n",
        "\n",
        "# context = \"\\n\\n\".join([doc.page_content for doc in test_faiss_docs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YnSosej0qY67",
      "metadata": {
        "id": "YnSosej0qY67"
      },
      "outputs": [],
      "source": [
        "# for doc in test_faiss_docs:\n",
        "#   print(\"============================\")\n",
        "#   print(doc.page_content)\n",
        "#   print(doc.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D-3sC_53yVup",
      "metadata": {
        "id": "D-3sC_53yVup"
      },
      "outputs": [],
      "source": [
        "# # Set Prompts\n",
        "# from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# prompt_template = \\\n",
        "# \"\"\"\n",
        "# You are a helpful assistant for question answering tasks.\n",
        "# Use the following pieces of retrieved context to answer the given question.\n",
        "# If you dont know the answer, just say that you dont know.\n",
        "# Use up to three sentenses to keep answer precise.\n",
        "\n",
        "# Question: {question}\n",
        "\n",
        "# Context: {context}\n",
        "# \"\"\"\n",
        "\n",
        "# prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "# # Invoke and pass in query and context\n",
        "# prompt = prompt_template.invoke(\n",
        "#     {\n",
        "#         \"context\": context,\n",
        "#         \"question\": question\n",
        "#     }\n",
        "# )\n",
        "# prompt.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yc15hssb1rXj",
      "metadata": {
        "id": "yc15hssb1rXj"
      },
      "outputs": [],
      "source": [
        "# # Generate Response\n",
        "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "# response = llm.invoke(prompt)\n",
        "\n",
        "# # Parse the response into well formated text\n",
        "# from langchain_core.output_parsers import StrOutputParser\n",
        "# parser = StrOutputParser()\n",
        "\n",
        "# res = parser.invoke(response)\n",
        "\n",
        "# print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WzF8C-ivUxmq",
      "metadata": {
        "id": "WzF8C-ivUxmq"
      },
      "source": [
        "## 4b. Agentic RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "znVMT4r8LvCs",
      "metadata": {
        "id": "znVMT4r8LvCs"
      },
      "outputs": [],
      "source": [
        "# Retriever Tool\n",
        "class RetrieverTool:\n",
        "    \"\"\"Wrapper around FAISS retriever for LangChain/OpenAI tools interface.\"\"\"\n",
        "\n",
        "    def __init__(self, faiss_store: FAISS, top_k: int = 12):\n",
        "        self.retriever: BaseRetriever = faiss_store.as_retriever(\n",
        "            search_kwargs={\"k\": top_k}\n",
        "        )\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        \"\"\"Retrieve top-k documents similar to the query.\"\"\"\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "        docs = self.retriever.invoke(query)\n",
        "\n",
        "        if not docs:\n",
        "            return \"No relevant documents found.\"\n",
        "\n",
        "        formatted_docs = \"\\n\".join(\n",
        "            [\n",
        "                f\"===== Document {i+1} =====\\n\"\n",
        "                f\"{doc.page_content}\\n\"\n",
        "                f\"Metadata: {doc.metadata}\\n\"\n",
        "                for i, doc in enumerate(docs)\n",
        "            ]\n",
        "        )\n",
        "        return formatted_docs\n",
        "\n",
        "    def as_tool(self) -> StructuredTool:\n",
        "        \"\"\"Convert to a LangChain StructuredTool usable by OpenAI agents.\"\"\"\n",
        "        return StructuredTool.from_function(\n",
        "            func=self.forward,\n",
        "            name=\"retriever\",\n",
        "            description=\"Retrieves semantically similar documents from a FAISS vector index given a natural language query.\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Hrdf2vVdL0Tj",
      "metadata": {
        "id": "Hrdf2vVdL0Tj"
      },
      "outputs": [],
      "source": [
        "# Calculator Tool for comparisons\n",
        "class CalculatorTool:\n",
        "    \"\"\"Tool to compute YoY or QoQ percentage changes from numeric data.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(input_str: str) -> str:\n",
        "        \"\"\"\n",
        "        Accepts a JSON string like:\n",
        "        {\n",
        "          \"data\": [{\"fiscal_year\": \"2022\", \"opex\": 7434.0}, ...],\n",
        "          \"metric_key\": \"opex\",\n",
        "          \"period_key\": \"fiscal_year\",\n",
        "          \"comparison_type\": \"yoy\"\n",
        "        }\n",
        "        Returns: JSON string with computed results.\n",
        "        \"\"\"\n",
        "        # Clean up formatting issues from the LLM\n",
        "        input_str = input_str.strip().strip(\"`\").strip(\"'\").strip('\"')\n",
        "\n",
        "        try:\n",
        "            params = json.loads(input_str)\n",
        "        except Exception as e:\n",
        "            return json.dumps({\"error\": f\"Invalid input JSON: {str(e)}\", \"received\": input_str})\n",
        "\n",
        "        # Input Structure\n",
        "        data = params.get(\"data\", [])\n",
        "        metric_key = params.get(\"metric_key\", \"opex\")\n",
        "        period_key = params.get(\"period_key\", \"fiscal_year\")\n",
        "        comparison_type = params.get(\"comparison_type\", \"yoy\")\n",
        "\n",
        "        # Handle dictionary-shaped data (like {\"2022\": 7434, ...})\n",
        "        if isinstance(data, dict):\n",
        "            data = [{period_key: k, metric_key: v} for k, v in data.items()]\n",
        "\n",
        "        if not isinstance(data, list):\n",
        "            return json.dumps({\"error\": \"Expected 'data' to be a list or dict of year:value pairs.\"})\n",
        "\n",
        "        # Compute percentage changes\n",
        "        results = []\n",
        "        for i, record in enumerate(data):\n",
        "            if i == 0:\n",
        "                pct_change = None\n",
        "            else:\n",
        "                prev_value = data[i - 1][metric_key]\n",
        "                curr_value = record[metric_key]\n",
        "                pct_change = ((curr_value - prev_value) / prev_value) * 100\n",
        "\n",
        "            results.append({\n",
        "                period_key: record[period_key],\n",
        "                metric_key: record[metric_key],\n",
        "                f\"{comparison_type}_change (%)\": round(pct_change, 2) if pct_change is not None else None,\n",
        "                \"units\": record.get(\"units\", \"millions USD\"),\n",
        "            })\n",
        "\n",
        "        return json.dumps(results, indent=2)\n",
        "\n",
        "    def as_tool(self) -> StructuredTool:\n",
        "        return StructuredTool.from_function(\n",
        "            func=self.forward,\n",
        "            name=\"calculator\",\n",
        "            description=(\n",
        "                \"Computes YoY or QoQ percentage changes. Input should be a JSON string containing data and comparison details.\"\n",
        "            ),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m6OvLbhUgoLq",
      "metadata": {
        "id": "m6OvLbhUgoLq"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGSMITH_KEY')\n",
        "# os.environ[\"LANGCHAIN_PROJECT\"] = \"AgentPerformance\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1QekVw22jrds",
      "metadata": {
        "id": "1QekVw22jrds"
      },
      "outputs": [],
      "source": [
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\") # Can be 'text-embedding-3-large'\n",
        "\n",
        "def build_faiss_index(chunked_docs):\n",
        "  embedding_model = OpenAIEmbeddings(embedding_model) # Can be 'text-embedding-3-large'\n",
        "\n",
        "  # FAISS Vector Index\n",
        "  faiss_store = FAISS.from_documents(chunked_docs, embedding_model)\n",
        "  faiss_store.save_local(\"faiss_index\")\n",
        "\n",
        "  # Load FAISS Vector Store\n",
        "  faiss_store = FAISS.load_local(\n",
        "      \"faiss_index\",\n",
        "      embeddings=embedding_model,\n",
        "      allow_dangerous_deserialization=True\n",
        "  )\n",
        "  return faiss_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "rbuOedjMkAkP",
      "metadata": {
        "id": "rbuOedjMkAkP"
      },
      "outputs": [],
      "source": [
        "def create_agent(faiss_store):\n",
        "  # Create Tools\n",
        "  retriever_tool = RetrieverTool(faiss_store=faiss_store, top_k=12).as_tool()\n",
        "  calculator_tool = CalculatorTool().as_tool()\n",
        "\n",
        "  # Initialize OpenAI LLM\n",
        "  openai_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "  # Create OpenAI-compatible agent that can use tools\n",
        "  agent = initialize_agent(\n",
        "      tools=[retriever_tool, calculator_tool],\n",
        "      llm=openai_llm,\n",
        "      agent_type=AgentType.OPENAI_FUNCTIONS,  # enables OpenAI’s function/tool calling\n",
        "      verbose=True,\n",
        "      handle_parsing_errors=True,\n",
        "  )\n",
        "  return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3QkslaOPjUeH",
      "metadata": {
        "id": "3QkslaOPjUeH"
      },
      "outputs": [],
      "source": [
        "def create_system_message():\n",
        "  return f\"\"\"\n",
        "You are a financial analyst agent that can use tools.\n",
        "\n",
        "Use the retriever tool when you need to fetch financial data. You can only call this tool ONCE.\n",
        "Use the calculator tool when you need to compute YoY or QoQ comparisons.\n",
        "\n",
        "Once done, return\n",
        "1. The **final structured JSON output** in this format:\n",
        "2. **Prose explanation**, converting the JSON output into a **formatted table**\n",
        "\n",
        "{{\n",
        "\"query\": \"...\",\n",
        "\"data_values\": [...],\n",
        "\"computed_values\": [...],\n",
        "\"citations\": [{{\"report\": \"...\", \"page\": ..., \"section\": \"...\"}}],\n",
        "\"tools\": [\"<list the tools you actually used>\"],\n",
        "\"tools_count\": <total number of tools used>\n",
        "}}\n",
        "\n",
        "Guidelines:\n",
        "- `data_values` contain the raw financial figures, corresponding fiscal years, and units retrieved directly from reports before any calculations.\n",
        "- `computed_values` include the calculated results (e.g., YoY or QoQ changes) together with the corresponding values from data_values.\n",
        "- Always include every period in `computed_values`, even if the change value is null.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "tGZJkRBE1ien",
      "metadata": {
        "id": "tGZJkRBE1ien"
      },
      "outputs": [],
      "source": [
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "class TimingCallback(BaseCallbackHandler):\n",
        "    def __init__(self):\n",
        "        self.tool_timings = []\n",
        "        self.current_tool = None\n",
        "        self.start_time = None\n",
        "        self.llm_start = None\n",
        "        self.reasoning_time = None\n",
        "\n",
        "    def on_tool_start(self, serialized, input_str, **kwargs):\n",
        "        self.current_tool = serialized.get(\"name\", \"UnknownTool\")\n",
        "        self.start_time = time.perf_counter()\n",
        "        print(f\"Tool start: {self.current_tool}\")\n",
        "\n",
        "    def on_tool_end(self, output, **kwargs):\n",
        "        duration = time.perf_counter() - self.start_time\n",
        "        print(f\"Tool end: {self.current_tool} ({duration:.3f}s)\")\n",
        "        self.tool_timings.append((self.current_tool, duration))\n",
        "        self.current_tool = None\n",
        "\n",
        "    def on_llm_start(self, *args, **kwargs):\n",
        "        self.llm_start = time.perf_counter()\n",
        "\n",
        "    def on_llm_end(self, response, **kwargs):\n",
        "        if self.llm_start:\n",
        "            duration = time.perf_counter() - self.llm_start\n",
        "            print(f\"LLM reasoning/generation: {duration:.3f}s\")\n",
        "            self.reasoning_time = duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NmfIuSUHPjmV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmfIuSUHPjmV",
        "outputId": "fa8052c9-ab6f-4886-8345-42edb3a5437c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "LLM reasoning/generation: 2.173s\n",
            "\u001b[32;1m\u001b[1;3mTo answer the question about Operating Expenses for the last three fiscal years with a year-on-year comparison, I need to retrieve the relevant financial data first. I will use the retriever tool to fetch the operating expenses data for the specified years.\n",
            "\n",
            "Action: retriever  \n",
            "Action Input: \"Operating Expenses for the last 3 fiscal years year-on-year comparison\"\n",
            "\u001b[0mTool start: retriever\n",
            "Tool end: retriever (0.432s)\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m===== Document 1 =====\n",
            "Table of Contents\n",
            "Operating Expenses\n",
            "Year Ended\n",
            "January 29, January 30, $ %\n",
            "2023 2022 Change Change\n",
            "($ in millions)\n",
            "Research and development expenses $ 7,339 $ 5,268 $ 2,071 39 %\n",
            "% of revenue 27.2 % 19.6 %\n",
            "Sales, general and administrative expenses 2,440 2,166 274 13 %\n",
            "% of revenue 9.1 % 8.0 %\n",
            "Acquisition termination cost 1,353 — 1,353 100 %\n",
            "% of revenue 5.0 % — %\n",
            "Total operating expenses $ 11,132 $ 7,434 $ 3,698 50 %\n",
            "% of revenue 41.3 % 27.6 %\n",
            "The increase in research and development expense for fiscal year 2023 was primarily driven by increased compensation, employee growth,\n",
            "engineering development costs, and data center infrastructure.\n",
            "The increase in sales, general and administrative expense for fiscal year 2023 was primarily driven by increased compensation and employee\n",
            "growth.\n",
            "Metadata: {'page': 43, 'report': 'FY23_10K', 'year': None, 'section': 'Item 1A. Risk', 'type': 'text'}\n",
            "\n",
            "===== Document 2 =====\n",
            "O perating Expenses\n",
            "Three Months E nded Nine Months Ended\n",
            "October 29, October 30, $ % October 29, October 30, $ %\n",
            "2023 2022 Change Change 2023 2022 Change Change\n",
            "($ in millio ns)\n",
            "Research and\n",
            "development expenses $ 2,294 $ 1,945 $ 349 18 % $ 6,210 $ 5,387 $ 823 15 %\n",
            "% of net revenue 12.7 % 32.8 % 16.0 % 25.7 %\n",
            "Sales, general and\n",
            "administrative expenses 689 631 58 9 % 1,942 1,815 127 7 %\n",
            "% of net revenue 3.8 % 10.6 % 5.0 % 8.7 %\n",
            "Acquisition termination\n",
            "cost — — — — % — 1,353 (1,353) (100) %\n",
            "% of net revenue — % — % — % 6.5 %\n",
            "Total operating\n",
            "expenses $ 2,983 $ 2,576 $ 407 16 % $ 8,152 $ 8,555 $ (403) (5) %\n",
            "% of net revenue 16.5 % 43.4 % 21.0 % 40.9 %\n",
            "The increases in research and development expenses and sales, general and administrative expenses for the third quarter and first nine months\n",
            "Metadata: {'page': 31, 'report': 'FY24Q3_10Q', 'year': None, 'section': 'ITEM 2. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS', 'type': 'text'}\n",
            "\n",
            "===== Document 3 =====\n",
            "Operating Expenses\n",
            "Year Ended\n",
            "$ %\n",
            "Jan 28, 2024 Jan 29, 2023 Change Change\n",
            "($ in millions)\n",
            "Research and development expenses $ 8,675 $ 7,339 $ 1,336 18 %\n",
            "% of net revenue 14.2 % 27.2 %\n",
            "Sales, general and administrative expenses 2,654 2,440 214 9 %\n",
            "% of net revenue 4.4 % 9.1 %\n",
            "Acquisition termination cost — 1,353 (1,353) (100)%\n",
            "% of net revenue — % 5.0 %\n",
            "Total operating expenses $ 11,329 $ 11,132 $ 197 2 %\n",
            "% of net revenue 18.6 % 41.3 %\n",
            "The increase in research and development expenses and sales, general and administrative expenses for fiscal year 2024 was primarily driven by compensation\n",
            "and benefits, including stock-based compensation, reflecting employee growth and compensation increases.\n",
            "Acquisition Termination Cost\n",
            "Metadata: {'page': 40, 'report': 'FY24_10K', 'year': None, 'section': 'Item 1A. Risk Factors', 'type': 'text'}\n",
            "\n",
            "===== Document 4 =====\n",
            "Operating income (loss)\t$\t10,262\t\t\t$\t1,493\t\t$\t(1,338)\t\t$\t10,417\t\n",
            "Three Months Ended October 30, 2022\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t3,816\t\t\t$\t2,115\t\t$\t—\t\t$\t5,931\n",
            "Metadata: {'page': 23, 'report': 'FY24Q3_10Q', 'year': None, 'section': 'NVIDIA CORPORATION AND SUBSIDIARIES\\nNOTES TO CONDENSED CONSOLIDATED FINANCIAL STATEMENTS', 'type': 'table'}\n",
            "\n",
            "===== Document 5 =====\n",
            "Critical Accounting Policies and Estimates\n",
            "Refer to Part II, Item 7, \"Critical Accounting Policies and Estimates\" of our Annual Report on Form 10-K for the fiscal year ended January 29,\n",
            "2023. There have been no material changes to our Critical Accounting Policies and Estimates.\n",
            "Results of Operations\n",
            "The following table sets forth, for the periods indicated, certain items in our Condensed Consolidated Statements of Income expressed as a\n",
            "percentage of revenue.\n",
            "Three Mon ths Ended Nine Mont hs Ended\n",
            "October 29, October 30, October 29, October 30,\n",
            "2023 2022 2023 2022\n",
            "Revenue 100.0 % 100.0 % 100.0 % 100.0 %\n",
            "Cost of revenue 26.0 46.4 29.1 44.9\n",
            "Gross profit 74.0 53.6 70.9 55.1\n",
            "Operating expenses\n",
            "Research and development 12.7 32.8 16.0 25.7\n",
            "Sales, general and administrative 3.8 10.6 5.0 8.7\n",
            "Metadata: {'page': 29, 'report': 'FY24Q3_10Q', 'year': None, 'section': 'ITEM 2. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS', 'type': 'text'}\n",
            "\n",
            "===== Document 6 =====\n",
            "Three Months Ended Jul 28, 2024\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t26,446\t\t$\t3,594\t\t$\t—\t\t$\t30,040\n",
            "Operating income (loss)\t$\t18,848\t\t$\t1,369\t\t$\t(1,575)\t\t$\t18,642\n",
            "\t\t\t\t\t\t\t\t\t\t\t\n",
            "Three Months Ended Jul 30, 2023\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t10,402\t\t$\t3,105\t\t$\t—\t\t$\t13,507\n",
            "Operating income (loss)\t$\t6,728\t\t$\t1,211\t\t$\t(1,139)\t\t$\t6,800\n",
            "\t\t\t\t\t\t\t\t\t\t\t\n",
            "Six Months Ended Jul 28, 2024\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t49,121\t\t$\t6,963\t\t$\t—\t\t$\t56,084\n",
            "Operating income (loss)\t$\t35,896\t\t$\t2,609\t\t$\t(2,954)\t\t$\t35,551\n",
            "\t\t\t\t\t\t\t\t\t\t\t\n",
            "Six Months Ended Jul 30, 2023\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t14,862\t\t$\t5,837\t\t$\t—\t\t$\t20,699\n",
            "Operating income (loss)\t$\t8,887\t\t$\t2,258\t\t$\t(2,204)\t\t$\t8,941\n",
            "Metadata: {'page': 21, 'report': 'FY25Q2_10Q', 'year': None, 'section': 'Item 1. Financial Statements (Unaudited)', 'type': 'table'}\n",
            "\n",
            "===== Document 7 =====\n",
            "Table of Contents\n",
            "Operating Expenses\n",
            "Year Ended\n",
            "January 30, January 31, $ %\n",
            "2022 2021 Change Change\n",
            "($ in millions)\n",
            "Research and development expenses $ 5,268 $ 3,924 $ 1,344 34 %\n",
            "% of net revenue 19.6 % 23.5 %\n",
            "Sales, general and administrative expenses 2,166 1,940 226 12 %\n",
            "% of net revenue 8.0 % 11.6 %\n",
            "Total operating expenses $ 7,434 $ 5,864 $ 1,570 27 %\n",
            "Research and Development\n",
            "Research and development expenses increased by 34% in fiscal year 2022 compared to fiscal year 2021, primarily driven by stock-based\n",
            "compensation, compensation-related costs associated with employee growth and higher infrastructure costs.\n",
            "Sales, General and Administrative\n",
            "Sales, general and administrative expenses increased by 12% in fiscal year 2022 compared to fiscal year 2021, primarily driven by stock-based\n",
            "Metadata: {'page': 37, 'report': 'FY22_10K', 'year': None, 'section': 'Item 1A. Risk Factors”,', 'type': 'text'}\n",
            "\n",
            "===== Document 8 =====\n",
            "Table of Contents\n",
            "The following table sets forth, for the periods indicated, certain items in our Consolidated Statements of Income expressed as a percentage of revenue.\n",
            "Year Ended\n",
            "Jan 28, 2024 Jan 29, 2023\n",
            "Revenue 100.0 % 100.0 %\n",
            "Cost of revenue 27.3 43.1\n",
            "Gross profit 72.7 56.9\n",
            "Operating expenses\n",
            "Research and development 14.2 27.2\n",
            "Sales, general and administrative 4.4 9.1\n",
            "Acquisition termination cost — 5.0\n",
            "Total operating expenses 18.6 41.3\n",
            "Operating income 54.1 15.6\n",
            "Interest income 1.4 1.0\n",
            "Interest expense (0.4) (1.0)\n",
            "Other, net 0.4 (0.1)\n",
            "Other income (expense), net 1.4 (0.1)\n",
            "Income before income tax 55.5 15.5\n",
            "Income tax expense (benefit) 6.6 (0.7)\n",
            "Net income 48.9 % 16.2 %\n",
            "Reportable Segments\n",
            "Revenue by Reportable Segments\n",
            "Year Ended\n",
            "$ %\n",
            "Jan 28, 2024 Jan 29, 2023 Change Change\n",
            "Metadata: {'page': 39, 'report': 'FY24_10K', 'year': None, 'section': 'Item 1A. Risk Factors', 'type': 'text'}\n",
            "\n",
            "===== Document 9 =====\n",
            "Year Ended January 29, 2023:\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t15,068\t$\t11,906\t$\t—\t$\t26,974\n",
            "Operating income (loss)\t$\t5,083\t$\t4,552\t$\t(5,411)\t$\t4,224\n",
            "\t\t\t\t\t\t\t\t\n",
            "Year Ended January 30, 2022:\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t11,046\t$\t15,868\t$\t—\t$\t26,914\n",
            "Operating income (loss)\t$\t4,598\t$\t8,492\t$\t(3,049)\t$\t10,041\n",
            "\t\t\t\t\t\t\t\t\n",
            "Year Ended January 31, 2021:\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t6,841\t$\t9,834\t$\t—\t$\t16,675\n",
            "Operating income (loss)\t$\t2,548\t$\t4,612\t$\t(2,628)\t$\t4,532\n",
            "Metadata: {'page': 85, 'report': 'FY23_10K', 'year': None, 'section': 'NVIDIA CORPORATION AND SUBSIDIARIES', 'type': 'table'}\n",
            "\n",
            "===== Document 10 =====\n",
            "2023. There have been no material changes to our Critical Accounting Policies and Estimates.\n",
            "Results of Operations\n",
            "The following table sets forth, for the periods indicated, certain items in our Condensed Consolidated Statements of Income expressed as a\n",
            "percentage of revenue.\n",
            "Three Months Ended Six Months Ended\n",
            "July 30, July 31, July 30, July 31,\n",
            "2023 2022 2023 2022\n",
            "Revenue 100.0 % 100.0 % 100.0 % 100.0 %\n",
            "Cost of revenue 29.9 56.5 31.8 44.3\n",
            "Gross profit 70.1 43.5 68.2 55.7\n",
            "Operating expenses\n",
            "Research and development 15.1 27.2 18.9 23.0\n",
            "Sales, general and administrative 4.7 8.8 6.1 7.9\n",
            "Acquisition termination cost — — — 9.0\n",
            "Total operating expenses 19.8 36.0 25.0 39.9\n",
            "Operating income 50.3 7.5 43.2 15.8\n",
            "Interest income 1.4 0.7 1.6 0.4\n",
            "Interest expense (0.5) (1.0) (0.6) (0.9)\n",
            "Metadata: {'page': 28, 'report': 'FY24Q2_10Q', 'year': None, 'section': 'ITEM 2. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS', 'type': 'text'}\n",
            "\n",
            "===== Document 11 =====\n",
            "Year Ended Jan 26, 2025\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t116,193\t\t$\t14,304\t\t$\t—\t\t$\t130,497\n",
            "Other segment items (1)\t33,318\t\t\t9,219\t\t\t\t\t\t\t\n",
            "Operating income (loss)\t$\t82,875\t\t$\t5,085\t\t$\t(6,507)\t\t$\t81,453\n",
            "\t\t\t\t\t\t\t\t\t\t\t\n",
            "Year Ended Jan 28, 2024\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t47,405\t\t$\t13,517\t\t$\t—\t\t$\t60,922\n",
            "Other segment items (1)\t15,389\t\t\t7,671\t\t\t\t\t\t\t\n",
            "Operating income (loss)\t$\t32,016\t\t$\t5,846\t\t$\t(4,890)\t\t$\t32,972\n",
            "\t\t\t\t\t\t\t\t\t\t\t\n",
            "Year Ended Jan 29, 2023\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t15,068\t\t$\t11,906\t\t$\t—\t\t$\t26,974\n",
            "Other segment items (1)\t9,985\t\t\t7,354\t\t\t\t\t\t\t\n",
            "Operating income (loss)\t$\t5,083\t\t$\t4,552\t\t$\t(5,411)\t\t$\t4,224\n",
            "Metadata: {'page': 78, 'report': 'FY25_10K', 'year': None, 'section': \"Item 9A. Our responsibility is to express opinions on the Company’s consolidated financial statements and on the Company's internal\", 'type': 'table'}\n",
            "\n",
            "===== Document 12 =====\n",
            "Three Months Ended Apr 28, 2024\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t22,675\t\t$\t3,369\t\t$\t—\t\t$\t26,044\n",
            "Operating income (loss)\t$\t17,047\t\t$\t1,241\t\t$\t(1,379)\t\t$\t16,909\n",
            "\t\t\t\t\t\t\t\t\t\t\t\n",
            "Three Months Ended Apr 30, 2023\t\t\t\t\t\t\t\t\t\t\t\n",
            "Revenue\t$\t4,460\t\t$\t2,732\t\t$\t—\t\t$\t7,192\n",
            "Operating income (loss)\t$\t2,160\t\t$\t1,046\t\t$\t(1,066)\t\t$\t2,140\n",
            "Metadata: {'page': 20, 'report': 'FY25Q1_10Q', 'year': None, 'section': 'Item 1. Financial Statements (Unaudited)', 'type': 'table'}\n",
            "\u001b[0m\n",
            "Thought:LLM reasoning/generation: 3.518s\n",
            "\u001b[32;1m\u001b[1;3mI have retrieved the operating expenses data for the last three fiscal years. Now, I will organize this data to compute the year-on-year changes.\n",
            "\n",
            "The retrieved data for total operating expenses is as follows:\n",
            "\n",
            "- **Fiscal Year 2024**: $11,329 million\n",
            "- **Fiscal Year 2023**: $11,132 million\n",
            "- **Fiscal Year 2022**: $7,434 million\n",
            "\n",
            "Next, I will calculate the year-on-year changes for these figures.\n",
            "\n",
            "Action: calculator  \n",
            "Action Input: '{\"data\": {\"2024\": 11329, \"2023\": 11132, \"2022\": 7434}, \"comparison\": \"YoY\"}'\n",
            "\u001b[0mTool start: calculator\n",
            "Tool end: calculator (0.001s)\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m[\n",
            "  {\n",
            "    \"fiscal_year\": \"2024\",\n",
            "    \"opex\": 11329,\n",
            "    \"yoy_change (%)\": null,\n",
            "    \"units\": \"millions USD\"\n",
            "  },\n",
            "  {\n",
            "    \"fiscal_year\": \"2023\",\n",
            "    \"opex\": 11132,\n",
            "    \"yoy_change (%)\": -1.74,\n",
            "    \"units\": \"millions USD\"\n",
            "  },\n",
            "  {\n",
            "    \"fiscal_year\": \"2022\",\n",
            "    \"opex\": 7434,\n",
            "    \"yoy_change (%)\": -33.22,\n",
            "    \"units\": \"millions USD\"\n",
            "  }\n",
            "]\u001b[0m\n",
            "Thought:LLM reasoning/generation: 11.586s\n",
            "\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: \n",
            "```json\n",
            "{\n",
            "  \"query\": \"Operating Expenses for the last 3 fiscal years year-on-year comparison\",\n",
            "  \"data_values\": [\n",
            "    {\"fiscal_year\": \"2024\", \"opex\": 11329, \"units\": \"millions USD\"},\n",
            "    {\"fiscal_year\": \"2023\", \"opex\": 11132, \"units\": \"millions USD\"},\n",
            "    {\"fiscal_year\": \"2022\", \"opex\": 7434, \"units\": \"millions USD\"}\n",
            "  ],\n",
            "  \"computed_values\": [\n",
            "    {\"fiscal_year\": \"2024\", \"opex\": 11329, \"yoy_change (%)\": null, \"units\": \"millions USD\"},\n",
            "    {\"fiscal_year\": \"2023\", \"opex\": 11132, \"yoy_change (%)\": -1.74, \"units\": \"millions USD\"},\n",
            "    {\"fiscal_year\": \"2022\", \"opex\": 7434, \"yoy_change (%)\": -33.22, \"units\": \"millions USD\"}\n",
            "  ],\n",
            "  \"citations\": [\n",
            "    {\"report\": \"FY24_10K\", \"page\": 40, \"section\": \"Item 1A. Risk Factors\"},\n",
            "    {\"report\": \"FY23_10K\", \"page\": 43, \"section\": \"Item 1A. Risk\"},\n",
            "    {\"report\": \"FY22_10K\", \"page\": 37, \"section\": \"Item 1A. Risk Factors\"}\n",
            "  ],\n",
            "  \"tools\": [\"retriever\", \"calculator\"],\n",
            "  \"tools_count\": 2\n",
            "}\n",
            "```\n",
            "\n",
            "**Prose Explanation:**\n",
            "\n",
            "The table below summarizes the operating expenses for the last three fiscal years along with their year-on-year changes:\n",
            "\n",
            "| Fiscal Year | Operating Expenses (in millions USD) | Year-on-Year Change (%) |\n",
            "|-------------|--------------------------------------|-------------------------|\n",
            "| 2024        | 11,329                               | N/A                     |\n",
            "| 2023        | 11,132                               | -1.74                   |\n",
            "| 2022        | 7,434                                | -33.22                  |\n",
            "\n",
            "- In fiscal year 2024, the total operating expenses were $11,329 million, which represents a slight decrease of 1.74% compared to fiscal year 2023.\n",
            "- Fiscal year 2023 saw a decrease of 33.22% in operating expenses compared to fiscal year 2022, where the expenses were $7,434 million. \n",
            "\n",
            "The data was retrieved from the financial reports for the respective years, and the year-on-year changes were calculated based on the operating expenses figures.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': [SystemMessage(content='\\nYou are a financial analyst agent that can use tools.\\n\\nUse the retriever tool when you need to fetch financial data. You can only call this tool ONCE.\\nUse the calculator tool when you need to compute YoY or QoQ comparisons.\\n\\nOnce done, return\\n1. The **final structured JSON output** in this format:\\n2. **Prose explanation**, converting the JSON output into a **formatted table**\\n\\n{\\n\"query\": \"...\",\\n\"data_values\": [...],\\n\"computed_values\": [...],\\n\"citations\": [{\"report\": \"...\", \"page\": ..., \"section\": \"...\"}],\\n\"tools\": [\"<list the tools you actually used>\"],\\n\"tools_count\": <total number of tools used>\\n}\\n\\nGuidelines:\\n- `data_values` contain the raw financial figures, corresponding fiscal years, and units retrieved directly from reports before any calculations.\\n- `computed_values` include the calculated results (e.g., YoY or QoQ changes) together with the corresponding values from data_values.\\n- Always include every period in `computed_values`, even if the change value is null.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.', additional_kwargs={}, response_metadata={})], 'output': '```json\\n{\\n  \"query\": \"Operating Expenses for the last 3 fiscal years year-on-year comparison\",\\n  \"data_values\": [\\n    {\"fiscal_year\": \"2024\", \"opex\": 11329, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2023\", \"opex\": 11132, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2022\", \"opex\": 7434, \"units\": \"millions USD\"}\\n  ],\\n  \"computed_values\": [\\n    {\"fiscal_year\": \"2024\", \"opex\": 11329, \"yoy_change (%)\": null, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2023\", \"opex\": 11132, \"yoy_change (%)\": -1.74, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2022\", \"opex\": 7434, \"yoy_change (%)\": -33.22, \"units\": \"millions USD\"}\\n  ],\\n  \"citations\": [\\n    {\"report\": \"FY24_10K\", \"page\": 40, \"section\": \"Item 1A. Risk Factors\"},\\n    {\"report\": \"FY23_10K\", \"page\": 43, \"section\": \"Item 1A. Risk\"},\\n    {\"report\": \"FY22_10K\", \"page\": 37, \"section\": \"Item 1A. Risk Factors\"}\\n  ],\\n  \"tools\": [\"retriever\", \"calculator\"],\\n  \"tools_count\": 2\\n}\\n```\\n\\n**Prose Explanation:**\\n\\nThe table below summarizes the operating expenses for the last three fiscal years along with their year-on-year changes:\\n\\n| Fiscal Year | Operating Expenses (in millions USD) | Year-on-Year Change (%) |\\n|-------------|--------------------------------------|-------------------------|\\n| 2024        | 11,329                               | N/A                     |\\n| 2023        | 11,132                               | -1.74                   |\\n| 2022        | 7,434                                | -33.22                  |\\n\\n- In fiscal year 2024, the total operating expenses were $11,329 million, which represents a slight decrease of 1.74% compared to fiscal year 2023.\\n- Fiscal year 2023 saw a decrease of 33.22% in operating expenses compared to fiscal year 2022, where the expenses were $7,434 million. \\n\\nThe data was retrieved from the financial reports for the respective years, and the year-on-year changes were calculated based on the operating expenses figures.'}\n",
            "\n",
            "  _     ._   __/__   _ _  _  _ _/_   Recorded: 02:25:24  Samples:  105\n",
            " /_//_/// /_\\ / //_// / //_'/ //     Duration: 17.806    CPU time: 0.156\n",
            "/   _/                      v5.1.1\n",
            "\n",
            "Profile at C:\\Users\\cryst\\AppData\\Local\\Temp\\ipykernel_12512\\3952156177.py:2\n",
            "\n",
            "\u001b[31m17.806\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m..\\..\\..\\Temp\\ipykernel_12512\\3952156177.py:1\u001b[0m\n",
            "└─ \u001b[31m17.717\u001b[0m AgentExecutor.invoke\u001b[0m  \u001b[2mlangchain\\chains\\base.py:128\u001b[0m\n",
            "      [34 frames hidden]  \u001b[2mlangchain, langchain_core, langchain_...\u001b[0m\n",
            "         \u001b[31m17.214\u001b[0m _SSLSocket.read\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
            "         \u001b[92m\u001b[2m0.432\u001b[0m StructuredTool._run\u001b[0m  \u001b[2mlangchain_core\\tools\\structured.py:70\u001b[0m\n",
            "         └─ \u001b[92m\u001b[2m0.432\u001b[0m \u001b[48;5;24m\u001b[38;5;15mRetrieverTool.forward\u001b[0m  \u001b[2m..\\..\\..\\Temp\\ipykernel_12512\\3457373586.py:10\u001b[0m\n",
            "            └─ \u001b[92m\u001b[2m0.432\u001b[0m VectorStoreRetriever.invoke\u001b[0m  \u001b[2mlangchain_core\\retrievers.py:217\u001b[0m\n",
            "                  [24 frames hidden]  \u001b[2mlangchain_core, langchain_community, ...\u001b[0m\n",
            "\n",
            "\n",
            "Total elapsed time: 17.80569910000486\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "\n",
        "prof = Profiler(async_mode=\"disabled\")\n",
        "prof.start()\n",
        "timing_callback = TimingCallback()\n",
        "\n",
        "start_total = time.perf_counter()\n",
        "\n",
        "# Build FAISS (if not yet built)\n",
        "# faiss_store = build_faiss_index(chunked_docs)\n",
        "\n",
        "# Load FAISS Vector Store\n",
        "faiss_store = FAISS.load_local(\n",
        "    \"faiss_index\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n",
        "\n",
        "agent = create_agent(faiss_store)\n",
        "\n",
        "# Run the Agent with a Query\n",
        "question = \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "system_prompt = create_system_message()\n",
        "\n",
        "response = agent.invoke({\n",
        "    \"input\": [\n",
        "        SystemMessage(content=system_prompt),\n",
        "        HumanMessage(content=question)\n",
        "    ]\n",
        "}, config={\"callbacks\": [timing_callback]})\n",
        "print(response)\n",
        "\n",
        "elapsed_total = time.perf_counter() - start_total\n",
        "\n",
        "prof.stop()\n",
        "print(prof.output_text(unicode=True, color=True))\n",
        "prof.last_session.save(\"02_Agent.pyisession\")\n",
        "html_output = prof.output_html()\n",
        "with open(\"02_Agent.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_output)\n",
        "print(f\"Total elapsed time: {elapsed_total}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ef8fabcb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def extract_json_and_prose(response_text: str):\n",
        "    \"\"\"\n",
        "    Extract both the JSON block and the prose explanation from an LLM response.\n",
        "    Returns (parsed_json, prose_text).\n",
        "    \"\"\"\n",
        "    pattern = re.compile(\n",
        "        r\"```json\\s*(\\{.*?\\})\\s*```(?:\\s*\\*\\*Prose Explanation:\\*\\*\\s*([\\s\\S]*))?\",\n",
        "        re.DOTALL\n",
        "    )\n",
        "    match = pattern.search(response_text)\n",
        "\n",
        "    if not match:\n",
        "        print(\"No JSON block found.\")\n",
        "        return None, None\n",
        "\n",
        "    json_str = match.group(1).strip()\n",
        "    prose = match.group(2).strip() if match.group(2) else \"\"\n",
        "\n",
        "    try:\n",
        "        data = json.loads(json_str)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON parse error: {e}\")\n",
        "        data = None\n",
        "\n",
        "\n",
        "    return data, prose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9599cab4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'```json\\n{\\n  \"query\": \"Operating Expenses for the last 3 fiscal years year-on-year comparison\",\\n  \"data_values\": [\\n    {\"fiscal_year\": \"2024\", \"opex\": 11329, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2023\", \"opex\": 11132, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2022\", \"opex\": 7434, \"units\": \"millions USD\"}\\n  ],\\n  \"computed_values\": [\\n    {\"fiscal_year\": \"2024\", \"opex\": 11329, \"yoy_change (%)\": null, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2023\", \"opex\": 11132, \"yoy_change (%)\": -1.74, \"units\": \"millions USD\"},\\n    {\"fiscal_year\": \"2022\", \"opex\": 7434, \"yoy_change (%)\": -33.22, \"units\": \"millions USD\"}\\n  ],\\n  \"citations\": [\\n    {\"report\": \"FY24_10K\", \"page\": 40, \"section\": \"Item 1A. Risk Factors\"},\\n    {\"report\": \"FY23_10K\", \"page\": 43, \"section\": \"Item 1A. Risk\"},\\n    {\"report\": \"FY22_10K\", \"page\": 37, \"section\": \"Item 1A. Risk Factors\"}\\n  ],\\n  \"tools\": [\"retriever\", \"calculator\"],\\n  \"tools_count\": 2\\n}\\n```\\n\\n**Prose Explanation:**\\n\\nThe table below summarizes the operating expenses for the last three fiscal years along with their year-on-year changes:\\n\\n| Fiscal Year | Operating Expenses (in millions USD) | Year-on-Year Change (%) |\\n|-------------|--------------------------------------|-------------------------|\\n| 2024        | 11,329                               | N/A                     |\\n| 2023        | 11,132                               | -1.74                   |\\n| 2022        | 7,434                                | -33.22                  |\\n\\n- In fiscal year 2024, the total operating expenses were $11,329 million, which represents a slight decrease of 1.74% compared to fiscal year 2023.\\n- Fiscal year 2023 saw a decrease of 33.22% in operating expenses compared to fiscal year 2022, where the expenses were $7,434 million. \\n\\nThe data was retrieved from the financial reports for the respective years, and the year-on-year changes were calculated based on the operating expenses figures.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7721d8c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "data, prose = extract_json_and_prose(response['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "221e9638",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Operating Expenses for the last 3 fiscal years year-on-year comparison',\n",
              " 'data_values': [{'fiscal_year': '2024',\n",
              "   'opex': 11329,\n",
              "   'units': 'millions USD'},\n",
              "  {'fiscal_year': '2023', 'opex': 11132, 'units': 'millions USD'},\n",
              "  {'fiscal_year': '2022', 'opex': 7434, 'units': 'millions USD'}],\n",
              " 'computed_values': [{'fiscal_year': '2024',\n",
              "   'opex': 11329,\n",
              "   'yoy_change (%)': None,\n",
              "   'units': 'millions USD'},\n",
              "  {'fiscal_year': '2023',\n",
              "   'opex': 11132,\n",
              "   'yoy_change (%)': -1.74,\n",
              "   'units': 'millions USD'},\n",
              "  {'fiscal_year': '2022',\n",
              "   'opex': 7434,\n",
              "   'yoy_change (%)': -33.22,\n",
              "   'units': 'millions USD'}],\n",
              " 'citations': [{'report': 'FY24_10K',\n",
              "   'page': 40,\n",
              "   'section': 'Item 1A. Risk Factors'},\n",
              "  {'report': 'FY23_10K', 'page': 43, 'section': 'Item 1A. Risk'},\n",
              "  {'report': 'FY22_10K', 'page': 37, 'section': 'Item 1A. Risk Factors'}],\n",
              " 'tools': ['retriever', 'calculator'],\n",
              " 'tools_count': 2}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "b658e609",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The table below summarizes the operating expenses for the last three fiscal years along with their year-on-year changes:\n",
            "\n",
            "| Fiscal Year | Operating Expenses (in millions USD) | Year-on-Year Change (%) |\n",
            "|-------------|--------------------------------------|-------------------------|\n",
            "| 2024        | 11,329                               | N/A                     |\n",
            "| 2023        | 11,132                               | -1.74                   |\n",
            "| 2022        | 7,434                                | -33.22                  |\n",
            "\n",
            "- In fiscal year 2024, the total operating expenses were $11,329 million, which represents a slight decrease of 1.74% compared to fiscal year 2023.\n",
            "- Fiscal year 2023 saw a decrease of 33.22% in operating expenses compared to fiscal year 2022, where the expenses were $7,434 million. \n",
            "\n",
            "The data was retrieved from the financial reports for the respective years, and the year-on-year changes were calculated based on the operating expenses figures.\n"
          ]
        }
      ],
      "source": [
        "prose = prose.encode('utf-8').decode('unicode_escape')\n",
        "print(prose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "VA-PuPsAetmF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA-PuPsAetmF",
        "outputId": "40238536-aa8b-4ebd-e37a-1edf989fcfaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Summary ===\n",
            "retriever            0.432s\n",
            "calculator           0.001s\n",
            "reasoning            11.586s\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Summary ===\")\n",
        "for name, t in timing_callback.tool_timings:\n",
        "    print(f\"{name:<20} {t:.3f}s\")\n",
        "print(f\"{'reasoning':<20} {timing_callback.reasoning_time:.3f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Gross Margin Trend (or NIM if Bank)\n",
        "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
        "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
        "\n",
        "*   Operating Expenses (Opex) YoY for 3 Years\n",
        "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
        "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
        "\n",
        "*   Operating Efficiency Ratio\n",
        "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement benchmark runner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5"
      },
      "outputs": [],
      "source": [
        "# Example instrumentation schema\n",
        "import pandas as pd\n",
        "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
        "logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
